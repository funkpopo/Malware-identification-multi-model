#!/usr/bin/env python
# coding: utf-8

# In[2]:


from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import os 
from tqdm import tqdm
import joblib


# In[3]:


def strip(data):
    columns = data.columns
    new_columns = []
    for i in range(len(columns)):
        new_columns.append(columns[i].strip())
    return new_columns


# In[4]:


Agreement_csv = ['bittorrent.csv',
                 'dns.csv',
                 'ftp.csv',
                 'httphttps.csv',
                 'pop3.csv',
                 'smtp.csv',
                 'ssh.csv',
                 'telnet.csv']


# In[5]:


path = '../Data'
for root, dirs, files in os.walk(path): 
    print(files)
    if files==[]:
        break
    csv = files


# In[6]:


csv = [i for i in csv if i not in Agreement_csv]


# In[7]:


data = pd.DataFrame()
for single_csv in csv:
    if 'csv' in single_csv:
        temp = pd.read_csv(os.path.join(path,single_csv))
    else:
        temp = pd.read_excel(os.path.join(path,single_csv))
    data = pd.concat([temp,data],axis=0)
data.columns = strip(data)


# In[8]:


Label_encoder = {data['Label'].unique()[i]:i for i in range(len(data['Label'].unique()))}


# In[9]:


data['Label']=data['Label'].apply(lambda x:Label_encoder[x])


# In[10]:


data


# In[11]:


positive_len = len(data[data.Label!=1])
negative = data[data['Label'] == 1].sample(n = positive_len)
data_balance = pd.concat([negative,data[data.Label!=1]]).reset_index()
input_data = data_balance[data_balance.columns[:-1]]
input_labels = data_balance['Label']


# In[12]:


def delete_inf(data,label):
    input_data_ = np.array(data)
    input_labels_ = np.array(label)
    inf = np.argwhere(input_data_==np.inf)[:,0]
    inf = list(set(inf))
    input_data_ = np.delete(input_data_,inf,axis=0)
    input_labels_ = np.delete(input_labels_,inf)
    return input_data_,input_labels_


# In[13]:


input_data, input_labels = delete_inf(input_data, input_labels)


# In[14]:


train_data,test_data,train_labels,test_labels = train_test_split(input_data,input_labels,train_size=0.8, test_size=0.2, random_state=41)


# In[29]:


##随机森林
clf = joblib.load('../Model/randomforest.pkl') 
logitis_RM = clf.predict_proba(test_data)


# In[30]:


##deepFM
deepfm = tf.saved_model.load("../Model/deepfm")
logitis_DM = deepfm.call(tf.convert_to_tensor(test_data,dtype=tf.float32))


# In[31]:


np.max(logitis_DM,axis=1)


# In[36]:


#neuranetwork
network = tf.saved_model.load("../Model/nuralnetwork")
logitis_NN = network.call(tf.convert_to_tensor(test_data,dtype=tf.float32))


# In[37]:


def TopkAccuracy(label,pred_logits,input_label,k):
    topk = np.argsort(np.array(pred_logits),axis=1)[:,-k:]
    nums=0
    cnt=0
    for index,values in enumerate(input_label):
        if values==label:
            nums+=1
            if values in topk[index]:
                cnt+=1
    return cnt/nums


# In[38]:


def CategoricalAccuracy(label,pred_logits,input_label):
    acc = 0
    num = 0
    predict = tf.argmax(pred_logits,axis=1)
    for index,values in enumerate(input_label):
        if values==label:
            num+=1
            if predict[index]==values:
                acc+=1
    return acc/num


# ***
# ## 模型准确率平均值

# In[39]:


acc = []
single_acc=[]
for label in range(6):
    avg_acc = 0
    for logits in [logitis_RM,logitis_DM,logitis_NN]:
        avg_acc += TopkAccuracy(label,logits,test_labels,1)
        single_acc.append(TopkAccuracy(label,logits,test_labels,1))
    avg_acc = avg_acc/3
    acc.append(avg_acc)
print(avg_acc)


# ***
# ## 集合模型准确率

# In[40]:


ensemble_logits = 4/6 * logitis_RM + 1/6 * logitis_DM + 1/6 * logitis_NN


# In[41]:


pred_label = np.argmax(ensemble_logits,axis=1)


# In[42]:


pred_output = np.max(ensemble_logits,axis=1)


# In[43]:


columns = list(data.columns)
columns[-1] = "Pred_label"


# In[44]:


columns.append("Probability")


# In[45]:


import csv
with open('./result.csv', 'w+') as f: # 采用b的方式处理可以省去很多问题
    writer = csv.writer(f)
    writer.writerows([columns])
    for index in range(len(test_data)):
        result = list(test_data[index])
        result.append(pred_label[index])
        result.append(pred_output[index])
        print(result)
        writer.writerows([list(result)])


# In[46]:


list(test_data[1]).append(1)


# In[47]:


ensemble_acc = []
for label in range(6):
    ensemble_acc.append(TopkAccuracy(label,ensemble_logits,test_labels,3))
ensemble_acc


# In[48]:


np.mean(np.array(ensemble_acc))


# ***
# ## 画图

# In[49]:


import matplotlib.pyplot as plt


# In[50]:


label = ['worm',
 'BENIGN',
 'XSS',
 'Sql Injection',
 'Trojan',
 'Overflow']
fig,ax = plt.subplots(figsize=(10,5))
b1 = ax.bar(label[0],ensemble_acc[0])
b2 = ax.bar(label[1],ensemble_acc[1])
b3 = ax.bar(label[2],ensemble_acc[2])
b4 = ax.bar(label[3],ensemble_acc[3])
b5 = ax.bar(label[4],ensemble_acc[4])
b6 = ax.bar(label[5],ensemble_acc[5])
for b in b1+b2+b3+b4+b5+b6:
    h = b.get_height()
    ax.text(b.get_x()+b.get_width()/2,h,'%f'%h,ha='center',va='bottom')
plt.xlabel('Label')
plt.ylabel('accuracy')


# In[ ]:




