#!/usr/bin/env python
# coding: utf-8

# In[1]:


import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import os 
from tqdm import tqdm


# In[2]:


os.environ['CUDA_VISIBLE_DEVICES'] = ''


# In[3]:


class FM_layer(tf.keras.layers.Layer):
    """
    自定义FM层
    @units 每个input的权重向量
    """
    def __init__(self, units):
        super(FM_layer, self).__init__()
        self.units = units

    def build(self, input_shape):
        self.w = self.add_variable(name='v', shape=[input_shape[-1], self.units],                                   initializer = tf.random_normal_initializer())

        self.liner_w = self.add_variable(name='l_w', shape=[input_shape[-1], self.units],                                   initializer = tf.random_normal_initializer())

        self.liner_b = self.add_variable(name='l_b', shape=[self.units],                                          initializer=tf.zeros_initializer())
    
    @tf.function
    def call(self, inputs):
        liner = tf.nn.sigmoid(tf.matmul(inputs, self.liner_w)+self.liner_b)
        output = tf.nn.sigmoid(0.5 * (tf.pow(tf.matmul(inputs, self.w), 2) - tf.matmul(tf.pow(inputs,2),tf.pow(self.w,2))))
        output = tf.concat([liner, output], axis=1)
        return output


# In[4]:


class Deep_FM(tf.keras.Model):
    def __init__(self):
        super(Deep_FM, self).__init__()
        self.layer1 = tf.keras.layers.Dense(units=128, activation=tf.nn.sigmoid)
        self.layer2 = tf.keras.layers.Dense(units=64, activation=tf.nn.relu)
        self.layer3 = tf.keras.layers.Dense(units=32, activation=tf.nn.relu)
        self.layer4 = tf.keras.layers.Dense(units=6, activation=tf.nn.relu)
        self.FM = FM_layer(units=40)
        self.layer5 = tf.keras.layers.Dense(units=6, activation=tf.nn.sigmoid)
    
    @tf.function
    def call(self, inputs):
        x_dnn = self.layer1(inputs)
        x_dnn = self.layer2(x_dnn)
        x_dnn = self.layer3(x_dnn)
        x_dnn = self.layer4(x_dnn)
        x_fm = self.FM(inputs)
        x_fm = self.layer5(x_fm)
        x_dnn
        x = x_dnn+x_fm
        x = tf.nn.softmax(x)
        return x


# ## 读取数据集

# In[5]:


def strip(data):
    columns = data.columns
    new_columns = []
    for i in range(len(columns)):
        new_columns.append(columns[i].strip())
    return new_columns


# In[6]:


path = './Data'
for root, dirs, files in os.walk(path):  
    if files==[]:
        break
    csv = files


# In[7]:


csv


# In[ ]:


data = pd.DataFrame()
for single_csv in csv:
    if 'csv' in single_csv:
        temp = pd.read_csv(os.path.join(path,single_csv))
    else:
        temp = pd.read_excel(os.path.join(path,single_csv))
    data = pd.concat([temp,data],axis=0)
data.columns = strip(data)


# In[ ]:


Label_encoder = {data['Label'].unique()[i]:i for i in range(len(data['Label'].unique()))}


# In[ ]:


Label_encoder


# In[ ]:


data['Label']=data['Label'].apply(lambda x:Label_encoder[x])


# In[ ]:


data.head(3)


# ## 构造平衡数据集

# In[ ]:


positive_len = len(data[data.Label!=1])


# In[ ]:


negative = data[data['Label'] == 1].sample(n = positive_len)


# In[ ]:


data_balance = pd.concat([negative,data[data.Label!=1]]).reset_index()


# In[ ]:


data_balance.columns


# In[ ]:


input_data = data_balance[data_balance.columns[:-1]]
input_labels = data_balance['Label']


# In[ ]:


input_data


# ### 数据标准化

# In[ ]:


def delete_inf(data,label):
    input_data_ = np.array(data)
    input_labels_ = np.array(label)
    inf = np.argwhere(input_data_==np.inf)[:,0]
    inf = list(set(inf))
    input_data_ = np.delete(input_data_,inf,axis=0)
    input_labels_ = np.delete(input_labels_,inf)
    return input_data_,input_labels_


# In[ ]:


input_data, input_labels = delete_inf(input_data, input_labels)


# In[ ]:


input_data.shape,input_labels.shape


# In[ ]:


# mean = np.mean(input_data,axis=0)
# max_ = np.max(input_data,axis=0)
# min_ = np.min(input_data,axis=0)

# s = np.sum((input_data - mean)**2,axis=0)
# input_data = (input_data - mean)/s

# input_data = (input_data-min_)/(max_-min_)


# In[ ]:


np.argwhere(input_data==np.inf)


# ***

# In[ ]:


train_data,test_data,train_labels,test_labels = train_test_split(input_data,input_labels,train_size=0.8, test_size=0.2, random_state=41)


# In[ ]:


deepfm = Deep_FM()
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)


# In[ ]:


train_data_keras = np.array(train_data)
test_data_keras = np.array(test_data)
y_train_keras = np.array(train_labels)
y_test_keras = np.array(test_labels)
batch_size=512


# In[ ]:


def onehot_embedding(label):
    onehot_dict = {0:[1,0,0,0,0,0],1:[0,1,0,0,0,0],2:[0,0,1,0,0,0],3:[0,0,0,1,0,0],4:[0,0,0,0,1,0],5:[0,0,0,0,0,1]}
    one_hot = []
    for i in label:
        one_hot.append(onehot_dict[i])
    return np.array(one_hot)


# In[ ]:


valid_data = [test_data_keras, onehot_embedding(y_test_keras)]


# In[ ]:


train_data_keras.shape
y_train_keras.shape


# In[ ]:


callback = [

#     tf.keras.callbacks.EarlyStopping(
#         monitor='val_categorical_accuracy', min_delta=0, patience=300, verbose=0, mode='auto',
#         baseline=None, restore_best_weights=True),
    tf.keras.callbacks.TensorBoard(
        log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False,
        update_freq='epoch', profile_batch=2, embeddings_freq=0,
        embeddings_metadata=None
        )
]


# In[ ]:


deepfm.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss=tf.keras.losses.CategoricalCrossentropy(),
    metrics=[tf.keras.metrics.CategoricalAccuracy()]
)
deepfm.fit(train_data_keras, onehot_embedding(y_train_keras), epochs=5000, batch_size=batch_size,          verbose=1,validation_data=valid_data,callbacks=callback)


# In[ ]:


model = tf.saved_model.load("Model/deepfm")


# In[ ]:


tf.saved_model.save(deepfm, "Model/deepfm")


# In[8]:


def TopkAccuracy(label,input_data,input_label,k):
    pred_logits = model.call(tf.convert_to_tensor(test_data_keras,dtype=tf.float32))
    topk = np.argsort(np.array(pred_logits),axis=1)[:,-k:]
    nums=0
    cnt=0
    for index,values in enumerate(input_label):
        if values==label:
            nums+=1
            if values in topk[index]:
                cnt+=1
    return cnt/nums


# In[9]:


def CategoricalAccuracy(label,intput_data,input_label):
    acc = 0
    num = 0
    pred_logits = model.call(tf.convert_to_tensor(test_data_keras,dtype=tf.float32))
    predict = tf.argmax(pred_logits,axis=1)
    for index,values in enumerate(input_label):
        if values==label:
            num+=1
            if predict[index]==values:
                acc+=1
    return acc/num


# In[10]:


import matplotlib.pyplot as plt


# In[11]:


acc = []
for label in range(6):
    acc.append(TopkAccuracy(label,test_data_keras,y_test_keras,1))
acc 


# In[ ]:


label = ['worm',
 'BENIGN',
 'XSS',
 'Sql Injection',
 'Trojan',
 'Overflow']


# In[ ]:


fig,ax = plt.subplots(figsize=(10,5))
b1 = ax.bar(label[0],acc[0])
b2 = ax.bar(label[1],acc[1])
b3 = ax.bar(label[2],acc[2])
b4 = ax.bar(label[3],acc[3])
b5 = ax.bar(label[4],acc[4])
b6 = ax.bar(label[5],acc[5])
for b in b1+b2+b3+b4+b5+b6:
    h = b.get_height()
    ax.text(b.get_x()+b.get_width()/2,h,'%f'%h,ha='center',va='bottom')
plt.xlabel('Label')
plt.ylabel('accuracy')


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




